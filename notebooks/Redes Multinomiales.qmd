---
title: "Redes multinomiales"
author: "Ebony Valadez A01645722"
format: 
   html:
     toc: true
     html-math-method: katex
     embed-resources: true
     self-contained-math: true
     df-print: kable
editor: visual
---

## Ejemplo: Transporte

```{r}
if (!requireNamespace("bnlearn", quietly = TRUE)) install.packages("bnlearn")
library(bnlearn)
```

```{r}
data = read.csv("/Users/ebonyvaladez/Analisis-de-incertidumbre/survey.csv", stringsAsFactors = TRUE)
head(data)
```

```{r}
nodes = c("A", "S", "E", "O", "R", "T")
dag <- empty.graph(nodes)
```

```{r}
arc_set = matrix(c("A", "E",
                   "S", "E",
                   "E", "O",
                   "E", "R",
                   "O", "T",
                   "R", "T"),
                 byrow = TRUE, ncol = 2,
                 dimnames = list(NULL, c("from", "to")))

```

```{r}
arcs(dag) = arc_set
```

```{r}
dag
```

```{r}
bn_mle = bn.fit(dag, data = data, method = "mle")
```

Ejemplo de uso:

```{r}
bn_mle$O
```

## **Prueba** G\^2

```{r}
ci.test("T", "E", c("O", "R"), test = "mi", data = data)
```

## χ2 de Pearson

```{r}
ci.test("T", "E", c("O", "R"), test = "x2", data = data)
```

Prueba de independencia (condicional):

```{r}
arc.strength(dag, data = data, criterion = "mi")
```

Lo anterior nos sirve para evaluar nodo por nodo.

## **Network scores**

### **Bayesian Information Criterion (BIC)**

$$
\text{BIC} = \log \left[ \hat{\mathbb{P}}(\text{Nodos}) \right] - \frac{d}{2} \log(n)
$$ El BIC combina qué tan probable es el modelo dado los datos (primer término) con una penalización por complejidad (segundo término).

```{r}
bnlearn::score(dag, data = data, type = "bic")
```

### Akaike Information Criterion (AIC)

$$
\text{AIC} = \log\left[\widehat{\mathbb{P}}(\text{Nodos})\right] - d
$$ El AIC es, al igual que el BIC, un criterio para comparar modelos estadísticos, pero usa una penalización distinta.

```{r}
bnlearn::score(dag, data = data, type = "aic")
```

### Hill Cimbling

Es un algoritmo de búsqueda local que sirve para encontrar una buena solución a un problema optimizando una función.

```{r}
best_dag = hc(data)
```

```{r}
modelstring(best_dag)
```

**Puede que no tenga sentido en la vida real**

```{r}
graphviz.plot(best_dag, shape = "ellipse")
```

Probamos la nueva dag con nuestros otros modelos de comparación. (Aunque ya sabemos que no tiene sentido)

```{r}
score(best_dag, data = data, type = "bic")
score(best_dag, data = data, type = "aic")
```

## Logic Sampling

```{r}
bn = bn.fit(best_dag,data=data)
```

```{r}
cpquery(bn, event = (T == "train" & S == "F"), evidence = (E == "uni"), n = 10^6)
```

## Likelihood weighting

```{r}
cpquery(bn, event = (T == "train" & S == "F"), evidence = list(E = "uni"), method = "lw")
```
```{r}
cpquery(bn, event = (T == "train"), evidence = ((S == "M") & (((A == "young") & (E == "uni")) | (A == "adult"))), n = 10^6)
```














